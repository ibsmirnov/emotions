{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "03807951-6fd4-4331-a78c-fea72cba1f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import glob\n",
    "\n",
    "def open_final(model_name):\n",
    "    with open(f'data/final_scores_{model_name}.pkl', 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0524c3c9-b035-498e-b658-153e8ea1b64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/dataset.csv', quoting=1, escapechar='\\\\', doublequote=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5ac416-dfc8-4f71-8b58-db7c9098cc0b",
   "metadata": {},
   "source": [
    "## Extending dataframe by adding emotions and sentiment based on mood labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1dfc1e45-465a-4559-bc75-7d3da2aefeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "emomap = {'Sadness': ['Sad', 'Lonely'],\n",
    "         'Anger': ['Angry', 'Annoyed', 'Frustrated', 'Furious'],\n",
    "         'Fear': ['Anxious', 'Stressed', 'Afraid', 'Nervous', 'Worried'],\n",
    "         'Affection': ['Loving', 'Caring', 'Supportive'],\n",
    "         'Happiness': ['Happy', 'Excited']}\n",
    "\n",
    "emomap_r = {}\n",
    "for emo in emomap:\n",
    "    for label in emomap[emo]:\n",
    "        emomap_r[label] = emo\n",
    "\n",
    "sentimap = {'Sadness': 'negative', 'Anger': 'negative', 'Fear': 'negative', 'Affection': 'positive', 'Happiness': 'positive'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa2d39dd-e1b7-4a75-b617-22bd0c15e733",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['emotion'] = df['mood'].map(emomap_r)\n",
    "df['sentiment'] = df['emotion'].map(sentimap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fcd6316-8a4a-465d-bf7e-909778015669",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/dataset_extended.csv', index=False, quoting=1, escapechar='\\\\', doublequote=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718a88db-c7c6-4a83-8060-043fce576362",
   "metadata": {},
   "source": [
    "## Computing errors\n",
    "Note that total error is not equal to valence error plus salience error. If for example the actual\n",
    "sentiment is negative but it is predicted to be positive in 33.3% of cases and neutral in 33.3% of cases\n",
    "then the valence error is 50%, the salience error is 50%, and the total error is 66.6%.\n",
    "The goal of this definition is to separate salience and valence errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7f8f28c5-6d8b-454f-baaa-866829cf6bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_errors(df, scores):\n",
    "    # Filter df to only include rows where id is in scores\n",
    "    valid_df = df[df['id'].isin(scores.keys())].copy()\n",
    "    \n",
    "    # If no valid rows, return zeros\n",
    "    if len(valid_df) == 0:\n",
    "        return {\"valence_error\": 0, \"salience_error\": 0}\n",
    "    \n",
    "    # Add predictions to the dataframe\n",
    "    valid_df['predicted'] = valid_df['id'].map(scores)\n",
    "    \n",
    "    # Create flags for different types of predictions\n",
    "    valid_df['is_neutral_pred'] = valid_df['predicted'] == 'neutral'\n",
    "    valid_df['is_valence_error'] = (valid_df['sentiment'] != valid_df['predicted']) & (~valid_df['is_neutral_pred'])\n",
    "    \n",
    "    # Valence error: wrong sign among non-neutral predictions\n",
    "    non_neutral_count = sum(~valid_df['is_neutral_pred'])\n",
    "    valence_error = sum(valid_df['is_valence_error']) / non_neutral_count if non_neutral_count > 0 else 0\n",
    "    \n",
    "    # Salience error: didn't fail at detecting valence but failed to detect a sentiment\n",
    "    potential_correct_count = sum(~valid_df['is_valence_error'])\n",
    "    neutral_count = sum(valid_df['is_neutral_pred'])\n",
    "    salience_error = neutral_count / potential_correct_count if potential_correct_count > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        \"valence_error\": valence_error,\n",
    "        \"salience_error\": salience_error\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2360c634-1ba8-474c-8643-873b156f336b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3f87a752-c0b2-4dd4-bdc0-30630763d683",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_group_errors(df, scores):\n",
    "    # Create empty list to store results\n",
    "    result_data = []\n",
    "    \n",
    "    # Define the levels and their possible values\n",
    "    levels = {\n",
    "        'sentiment': ['positive', 'negative'],\n",
    "        'emotion': df['emotion'].unique().tolist(),  # Get all unique emotion values\n",
    "        'mood': df['mood'].unique().tolist()         # Get all unique mood values\n",
    "    }\n",
    "    \n",
    "    # Iterate through sex values\n",
    "    for sex_value in [0, 1]:\n",
    "        df_sex = df[df['sex'] == sex_value]\n",
    "        \n",
    "        # Iterate through levels (sentiment, emotion, mood)\n",
    "        for level, level_values in levels.items():\n",
    "            # Iterate through each possible value within the level\n",
    "            for level_value in level_values:\n",
    "                # Filter the dataframe\n",
    "                df_filtered = df_sex[df_sex[level] == level_value]\n",
    "                    \n",
    "                # Compute errors for this subset\n",
    "                errors = compute_errors(df_filtered, scores)\n",
    "                \n",
    "                # Add valence error to results\n",
    "                result_data.append({\n",
    "                    'sex': sex_value,\n",
    "                    'level': level,\n",
    "                    'level_value': level_value,\n",
    "                    'error_type': 'valence',\n",
    "                    'error_value': errors['valence_error']\n",
    "                })\n",
    "                \n",
    "                # Add salience error to results\n",
    "                result_data.append({\n",
    "                    'sex': sex_value,\n",
    "                    'level': level,\n",
    "                    'level_value': level_value,\n",
    "                    'error_type': 'salience',\n",
    "                    'error_value': errors['salience_error']\n",
    "                })\n",
    "    \n",
    "    # Create DataFrame from the collected data\n",
    "    result_df = pd.DataFrame(result_data)\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd928fa-2601-4702-8802-1abf91ec9602",
   "metadata": {},
   "source": [
    "Note that 0 is man and 1 is woman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "88b2d473-ebf8-4429-b845-683796671624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/final_scores_vader.pkl\n",
      "data/final_scores_olmo.pkl\n",
      "data/final_scores_falcon.pkl\n",
      "data/final_scores_pysentimiento_senti.pkl\n",
      "data/final_scores_hartmann.pkl\n",
      "data/final_scores_leia.pkl\n",
      "data/final_scores_cardif.pkl\n",
      "data/final_scores_llama8.pkl\n",
      "data/final_scores_siebert.pkl\n",
      "data/final_scores_mistral.pkl\n",
      "data/final_scores_granite.pkl\n",
      "data/final_scores_pysentimiento_emo.pkl\n",
      "data/final_scores_nrc.pkl\n",
      "data/final_scores_qwen.pkl\n",
      "data/final_scores_liwc.pkl\n",
      "data/final_scores_llama70.pkl\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/dataset_extended.csv', quoting=1, escapechar='\\\\', doublequote=True)\n",
    "\n",
    "model_files = glob.glob('data/final_scores_*.pkl')\n",
    "\n",
    "result = []\n",
    "\n",
    "for model_file in model_files:\n",
    "    print(model_file)\n",
    "    model_name = model_file.split('final_scores_')[1].split('.pkl')[0]\n",
    "    \n",
    "    scores = open_final(model_name)\n",
    "    \n",
    "    errors = compute_group_errors(df, scores)\n",
    "    errors['model'] = model_name\n",
    "    \n",
    "    result.append(errors)\n",
    "\n",
    "result = pd.concat(result, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "60980306-dc29-4cc3-9ec6-3118b40c5c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_types = {\n",
    "    'dictionary': ['liwc', 'nrc', 'vader'],\n",
    "    'llm': ['mistral', 'falcon', 'llama8', 'llama70', 'olmo', 'qwen', 'granite'],\n",
    "    'ml': ['cardif', 'hartmann', 'leia', 'pysentimiento_emo', 'pysentimiento_senti', 'siebert']\n",
    "}\n",
    "\n",
    "model_type_map = {}\n",
    "for model_type, models in model_types.items():\n",
    "    for model in models:\n",
    "        model_type_map[model] = model_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1359faa4-4a1a-4374-84ee-5134860b0d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result['model_type'] = result['model'].map(model_type_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8aeeb12b-c776-4845-af76-1737c02023c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('data/errors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a5f054-26e0-4c32-a99f-3775ff5581e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
